<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Python Ollama File | Mr Ash Co</title>
<meta name=keywords content="python,ollama,artificial-intelligence,natural-language-processing,file-reading,automation,scripting,machine-learning,programming-languages,coding-tutorials"><meta name=description content="Python and Ollama: Unlocking Local Files' Secrets! Learn how to harness the power of AI-empowered chatbot Ollama with Python scripting. Discover how to read text files, play audio clips, and display images - all without leaving your terminal window. Dive into this comprehensive guide today!"><meta name=author content="Ash"><link rel=canonical href=//localhost:1313/python-ollama-file/><meta name=google-site-verification content="G-XL842W0SQL"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.44b1553ba9937dff369242df7b6fc679a3e9bb446b6348d764bf00ad4733c2fb.css integrity="sha256-RLFVO6mTff82kkLfe2/GeaPpu0RrY0jXZL8ArUczwvs=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.acb54fd32bbc1982428b8850317e45d076b95012730a5936667e6bc21777692a.js integrity="sha256-rLVP0yu8GYJCi4hQMX5F0Ha5UBJzClk2Zn5rwhd3aSo=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href="https://p146.p4.n0.cdn.getcloudapp.com/items/Jrum0N6q/4ab8cbb7-d222-4c3c-963d-f0ec6c30568c.jpg?source=viewer&amp;v=db94595858aad20b777e4f130cbe5006"><link rel=icon type=image/png sizes=16x16 href=//localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=//localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=//localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=//localhost:1313/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=//localhost:1313/python-ollama-file/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-XL842W0SQL"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-XL842W0SQL")}</script><meta property="og:title" content="Python Ollama File"><meta property="og:description" content="Python and Ollama: Unlocking Local Files' Secrets! Learn how to harness the power of AI-empowered chatbot Ollama with Python scripting. Discover how to read text files, play audio clips, and display images - all without leaving your terminal window. Dive into this comprehensive guide today!"><meta property="og:type" content="article"><meta property="og:url" content="//localhost:1313/python-ollama-file/"><meta property="og:image" content="https://i.imgur.com/MM0giTM.jpeg"><meta property="article:section" content="post"><meta property="article:published_time" content="2024-06-29T00:00:00+00:00"><meta property="article:modified_time" content="2024-06-29T00:00:00+00:00"><meta property="og:site_name" content="Mr Ash Co"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://i.imgur.com/MM0giTM.jpeg"><meta name=twitter:title content="Python Ollama File"><meta name=twitter:description content="Python and Ollama: Unlocking Local Files' Secrets! Learn how to harness the power of AI-empowered chatbot Ollama with Python scripting. Discover how to read text files, play audio clips, and display images - all without leaving your terminal window. Dive into this comprehensive guide today!"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"//localhost:1313/post/"},{"@type":"ListItem","position":2,"name":"Python Ollama File","item":"//localhost:1313/python-ollama-file/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Python Ollama File","name":"Python Ollama File","description":"Python and Ollama: Unlocking Local Files' Secrets! Learn how to harness the power of AI-empowered chatbot Ollama with Python scripting. Discover how to read text files, play audio clips, and display images - all without leaving your terminal window. Dive into this comprehensive guide today!","keywords":["python","ollama","artificial-intelligence","natural-language-processing","file-reading","automation","scripting","machine-learning","programming-languages","coding-tutorials"],"articleBody":"Reading Local Files with Python and Ollama In this tutorial, we’ll walk through how to read local files using Python in conjunction with ollama, a tool that enables interaction with AI models on your local system. Whether you’re a beginner or looking to integrate AI locally, this guide will help you get started.\nRequirements Before diving in, ensure you have the following set up:\nPython Installation: If you haven’t installed Python yet, you can easily do so on Windows by using Win-get install Python. Verify the installation by checking the version with python --version. ollama Installation: ollama is crucial for this setup. Install it using your preferred method, such as via Win-get or directly from the Microsoft Store using the provided ID. Environment Variables Setup: If ollama doesn’t work out of the box, configure it in your environment variables. A simple way to do this is through Powertoys’ environment variables program, adding the installation path. Getting Started with Ollama Exploring ollama Resources:\nVisit ollama’s official website to explore available models and documentation. ollama acts as a host for various AI models, making it versatile for different applications. Navigate to the ollama Python GitHub repository, which provides the Python library dedicated to integrating with the ollama API. Choosing a Model:\nReview the list of models supported by ollama. Depending on your hardware capabilities and requirements, select a model that suits your needs. For simplicity, this tutorial uses the Q-when-to model, known for its lightweight nature, which makes it easy to run locally. Downloading the Model:\nFollow the provided commands to download your chosen model from ollama’s repository or library. This step ensures you have the necessary resources locally available for your AI interactions. Setting Up Your Python Script Creating Your Python Script: Open your preferred code editor and create a new Python file (app.py in this case). Begin by importing ollama to enable interaction with the installed model. import ollama note = 'notes.md' with open(note, 'r') as file: content = file.read() my_prompt = f'This is a personal note, what is it about? {content}' response = ollama.generate(model='qwen:0.5b', prompt=my_prompt) actual_response = response['response'] print(actual_response) Reading the Local File: Before diving into ollama integration, ensure you have a local file to read. For this tutorial, a sample text file (notes.md) contains text that we’ll use as input for our AI model. This is a note. I like dolphins. And I want to ride one, one day... Implementing the Script:\nUse Python’s file handling capabilities to read the content of notes.md. Store this content in a variable (content) to be used as input for the ollama model. Interacting with ollama:\nUtilize ollama’s generate function to send prompts to the AI model. In this script, define a prompt (my_prompt) using the content read from notes.md. Call ollama’s generate method with the specified model and prompt to receive a response. Displaying the Output:\nExtract and print the response from the ollama-generated output. This final step demonstrates how the AI interprets and generates insights based on the input provided. Frequently Asked Questions Here are some common queries addressed:\nUsing ollama in Python: Yes, ollama offers a dedicated Python library for seamless integration. Purpose of ollama: It serves as a local AI model host, enabling secure and private AI interactions without relying on external servers. ollama’s Suitability: Ideal for integrating AI locally, especially beneficial for handling sensitive data or maintaining privacy concerns. ollama’s Interface: ollama supports both GUI and command-line interfaces, offering flexibility based on user preference. GPU Support: ollama supports various GPUs, enhancing performance for AI tasks that benefit from GPU acceleration. Conclusion By following this straightforward guide, you’ve learned how to leverage Python and ollama to read and interpret local files using AI. This setup empowers you to explore AI applications locally, ensuring data privacy and operational efficiency. For more details, refer to ollama’s documentation and resources, or experiment with different models to suit your specific needs.\nStart your journey into local AI integration today with Python and ollama, enhancing your projects with powerful AI capabilities right from your own machine.\nLinks:\nhttps://ollama.com/ https://github.com/ollama/ollama https://github.com/ollama/ollama-python https://ollama.com/library/qwen2:0.5b https://github.com/ollama/ollama/blob/main/docs/gpu.md Thanks for reading, if you like, here’s a video of the whole process too.\n","wordCount":"693","inLanguage":"en","image":"https://i.imgur.com/MM0giTM.jpeg","datePublished":"2024-06-29T00:00:00Z","dateModified":"2024-06-29T00:00:00Z","author":{"@type":"Person","name":"Ash"},"mainEntityOfPage":{"@type":"WebPage","@id":"//localhost:1313/python-ollama-file/"},"publisher":{"@type":"Organization","name":"Mr Ash Co","logo":{"@type":"ImageObject","url":"https://p146.p4.n0.cdn.getcloudapp.com/items/Jrum0N6q/4ab8cbb7-d222-4c3c-963d-f0ec6c30568c.jpg?source=viewer\u0026v=db94595858aad20b777e4f130cbe5006"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=//localhost:1313/ accesskey=h title="mrashco (Alt + H)">mrashco</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=//localhost:1313/post title=posts><span>posts</span></a></li><li><a href=https://notes.mrash.co title=notes><span>notes</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://mrashco.substack.com title=letters><span>letters</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=//localhost:1313/search title=" (Alt + /)" accesskey=/><span><svg xmlns="http://www.w3.org/2000/svg" width="17.5" height="17.5" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="11" cy="11" r="8"/><line x1="21" y1="21" x2="16.65" y2="16.65"/></svg></span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=//localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=//localhost:1313/post/>Posts</a></div><h1 class=post-title>Python Ollama File</h1><div class=post-description>Python and Ollama: Unlocking Local Files' Secrets! Learn how to harness the power of AI-empowered chatbot Ollama with Python scripting. Discover how to read text files, play audio clips, and display images - all without leaving your terminal window. Dive into this comprehensive guide today!</div><div class=post-meta><span title='2024-06-29 00:00:00 +0000 UTC'>29/06/2024</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;693 words&nbsp;·&nbsp;Ash&nbsp;|&nbsp;<a href=https://github.com/mrashco/mrash.co/tree/main/content/post/2024/python-ollama-file.md rel="noopener noreferrer" target=_blank>Suggest Edits</a></div></header><figure class=entry-cover><img loading=lazy src=https://i.imgur.com/MM0giTM.jpeg alt></figure><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#requirements>Requirements</a></li><li><a href=#getting-started-with-ollama>Getting Started with Ollama</a></li><li><a href=#setting-up-your-python-script>Setting Up Your Python Script</a></li><li><a href=#frequently-asked-questions>Frequently Asked Questions</a></li><li><a href=#conclusion>Conclusion</a></li></ul></nav></div></details></div><div class=post-content><h1 id=reading-local-files-with-python-and-ollama>Reading Local Files with Python and Ollama<a hidden class=anchor aria-hidden=true href=#reading-local-files-with-python-and-ollama>#</a></h1><p>In this tutorial, we&rsquo;ll walk through how to read local files using Python in conjunction with ollama, a tool that enables interaction with AI models on your local system. Whether you&rsquo;re a beginner or looking to integrate AI locally, this guide will help you get started.</p><h2 id=requirements>Requirements<a hidden class=anchor aria-hidden=true href=#requirements>#</a></h2><p>Before diving in, ensure you have the following set up:</p><ul><li><strong>Python Installation</strong>: If you haven&rsquo;t installed Python yet, you can easily do so on Windows by using <code>Win-get install Python</code>. Verify the installation by checking the version with <code>python --version</code>.</li><li><strong>ollama Installation</strong>: ollama is crucial for this setup. Install it using your preferred method, such as via <code>Win-get</code> or directly from the Microsoft Store using the provided ID.</li><li><strong>Environment Variables Setup</strong>: If ollama doesn&rsquo;t work out of the box, configure it in your environment variables. A simple way to do this is through Powertoys&rsquo; environment variables program, adding the installation path.</li></ul><h2 id=getting-started-with-ollama>Getting Started with Ollama<a hidden class=anchor aria-hidden=true href=#getting-started-with-ollama>#</a></h2><ol><li><p><strong>Exploring ollama Resources</strong>:</p><ul><li>Visit ollama&rsquo;s official website to explore available models and documentation. ollama acts as a host for various AI models, making it versatile for different applications.</li><li>Navigate to the ollama Python GitHub repository, which provides the Python library dedicated to integrating with the ollama API.</li></ul></li><li><p><strong>Choosing a Model</strong>:</p><ul><li>Review the list of models supported by ollama. Depending on your hardware capabilities and requirements, select a model that suits your needs.</li><li>For simplicity, this tutorial uses the Q-when-to model, known for its lightweight nature, which makes it easy to run locally.</li></ul></li><li><p><strong>Downloading the Model</strong>:</p><ul><li>Follow the provided commands to download your chosen model from ollama&rsquo;s repository or library. This step ensures you have the necessary resources locally available for your AI interactions.</li></ul></li></ol><h2 id=setting-up-your-python-script>Setting Up Your Python Script<a hidden class=anchor aria-hidden=true href=#setting-up-your-python-script>#</a></h2><ol><li><strong>Creating Your Python Script</strong>:<ul><li>Open your preferred code editor and create a new Python file (<code>app.py</code> in this case).</li><li>Begin by importing ollama to enable interaction with the installed model.</li></ul></li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>ollama</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>note</span> <span class=o>=</span> <span class=s1>&#39;notes.md&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>note</span><span class=p>,</span> <span class=s1>&#39;r&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>file</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>content</span> <span class=o>=</span> <span class=n>file</span><span class=o>.</span><span class=n>read</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>my_prompt</span> <span class=o>=</span> <span class=sa>f</span><span class=s1>&#39;This is a personal note, what is it about? </span><span class=si>{</span><span class=n>content</span><span class=si>}</span><span class=s1>&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>response</span> <span class=o>=</span> <span class=n>ollama</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=s1>&#39;qwen:0.5b&#39;</span><span class=p>,</span> <span class=n>prompt</span><span class=o>=</span><span class=n>my_prompt</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>actual_response</span> <span class=o>=</span> <span class=n>response</span><span class=p>[</span><span class=s1>&#39;response&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>actual_response</span><span class=p>)</span>
</span></span></code></pre></div><ol start=2><li><strong>Reading the Local File</strong>:<ul><li>Before diving into ollama integration, ensure you have a local file to read. For this tutorial, a sample text file (<code>notes.md</code>) contains text that we&rsquo;ll use as input for our AI model.</li></ul></li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-markdown data-lang=markdown><span class=line><span class=cl>This is a note.
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>I like dolphins.
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>And I want to ride one, one day...
</span></span></code></pre></div><ol start=3><li><p><strong>Implementing the Script</strong>:</p><ul><li>Use Python&rsquo;s file handling capabilities to read the content of <code>notes.md</code>. Store this content in a variable (<code>content</code>) to be used as input for the ollama model.</li></ul></li><li><p><strong>Interacting with ollama</strong>:</p><ul><li>Utilize ollama&rsquo;s <code>generate</code> function to send prompts to the AI model. In this script, define a prompt (<code>my_prompt</code>) using the content read from <code>notes.md</code>.</li><li>Call ollama&rsquo;s <code>generate</code> method with the specified model and prompt to receive a response.</li></ul></li><li><p><strong>Displaying the Output</strong>:</p><ul><li>Extract and print the response from the ollama-generated output. This final step demonstrates how the AI interprets and generates insights based on the input provided.</li></ul></li></ol><h2 id=frequently-asked-questions>Frequently Asked Questions<a hidden class=anchor aria-hidden=true href=#frequently-asked-questions>#</a></h2><p>Here are some common queries addressed:</p><ul><li><strong>Using ollama in Python</strong>: Yes, ollama offers a dedicated Python library for seamless integration.</li><li><strong>Purpose of ollama</strong>: It serves as a local AI model host, enabling secure and private AI interactions without relying on external servers.</li><li><strong>ollama&rsquo;s Suitability</strong>: Ideal for integrating AI locally, especially beneficial for handling sensitive data or maintaining privacy concerns.</li><li><strong>ollama&rsquo;s Interface</strong>: ollama supports both GUI and command-line interfaces, offering flexibility based on user preference.</li><li><strong>GPU Support</strong>: ollama supports various GPUs, enhancing performance for AI tasks that benefit from GPU acceleration.</li></ul><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>By following this straightforward guide, you&rsquo;ve learned how to leverage Python and ollama to read and interpret local files using AI. This setup empowers you to explore AI applications locally, ensuring data privacy and operational efficiency. For more details, refer to ollama&rsquo;s documentation and resources, or experiment with different models to suit your specific needs.</p><p>Start your journey into local AI integration today with Python and ollama, enhancing your projects with powerful AI capabilities right from your own machine.</p><p>Links:</p><ul><li><a href=https://ollama.com/>https://ollama.com/</a></li><li><a href=https://github.com/ollama/ollama>https://github.com/ollama/ollama</a></li><li><a href=https://github.com/ollama/ollama-python>https://github.com/ollama/ollama-python</a></li><li><a href=https://ollama.com/library/qwen2:0.5b>https://ollama.com/library/qwen2:0.5b</a></li><li><a href=https://github.com/ollama/ollama/blob/main/docs/gpu.md>https://github.com/ollama/ollama/blob/main/docs/gpu.md</a></li></ul><hr><p>Thanks for reading, if you like, here&rsquo;s a video of the whole process too.</p><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen loading=eager referrerpolicy=strict-origin-when-cross-origin src="https://www.youtube.com/embed/IsEYXyMkRF8?autoplay=0&controls=1&end=0&loop=0&mute=0&start=0" style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 title="YouTube video"></iframe></div><br><iframe src=https://mrashco.substack.com/embed width=100% height=320 style="border:1px solid #eee;background:#f5f5f5;border-radius:12.5px" frameborder=0 scrolling=no></iframe></div><footer class=post-footer><ul class=post-tags><li><a href=//localhost:1313/tags/python/>Python</a></li><li><a href=//localhost:1313/tags/ollama/>Ollama</a></li><li><a href=//localhost:1313/tags/artificial-intelligence/>Artificial-Intelligence</a></li><li><a href=//localhost:1313/tags/natural-language-processing/>Natural-Language-Processing</a></li><li><a href=//localhost:1313/tags/file-reading/>File-Reading</a></li><li><a href=//localhost:1313/tags/automation/>Automation</a></li><li><a href=//localhost:1313/tags/scripting/>Scripting</a></li><li><a href=//localhost:1313/tags/machine-learning/>Machine-Learning</a></li><li><a href=//localhost:1313/tags/programming-languages/>Programming-Languages</a></li><li><a href=//localhost:1313/tags/coding-tutorials/>Coding-Tutorials</a></li></ul><nav class=paginav><a class=prev href=//localhost:1313/regresshion/><span class=title>« Prev</span><br><span>RegreSSHion (2006's OpenSSH Vuln is Back Again)</span>
</a><a class=next href=//localhost:1313/cybersec-beginner/><span class=title>Next »</span><br><span>Cyber Security for Beginners</span></a></nav></footer></article></main><footer class=footer><span>Made with ♥ from Australia</span> •
<span>&copy; 2017-2024 <a href=/policies>Policies</a><br>Site by <a href=//localhost:1313/>Mr Ash Co</a></span>
<span>• Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a>
x
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>const checkboxes=document.querySelectorAll('input[type="checkbox"]');checkboxes.forEach(e=>{e.removeAttribute("disabled")})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>